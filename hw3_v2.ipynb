{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import DatasetFolder\nfrom PIL import Image\nfrom torch.utils.data import ConcatDataset,DataLoader,Subset,Dataset\nimport gc\n\n#数据增强\ntrain_tfm = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(180),\n    transforms.RandomGrayscale(),\n    transforms.ToTensor(),\n    \n])\n\ntest_tfm = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])\n\nbatch_size = 128\n\ndef load_pic(x):\n    return Image.open(x)\n\ntrain_set_1 = DatasetFolder(\"/kaggle/input/dataset/food-11/training/labeled\", lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm)\ntrain_set_2 = DatasetFolder(\"/kaggle/input/dataset/food-11/training/labeled\", lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\nvalid_set = DatasetFolder(\"/kaggle/input/dataset/food-11/validation\", lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\nunlabeled_set = DatasetFolder(\"/kaggle/input/dataset/food-11/training/unlabeled\", lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm)\n\ntest_set = DatasetFolder(\"/kaggle/input/dataset/food-11/testing\", lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\ntrain_set = ConcatDataset([train_set_1, train_set_2]) \nprint(len(train_set))\n# Construct data loaders.\ntrain_loader = DataLoader(train_set, batch_size=batch_size,  num_workers=8, pin_memory=True,shuffle=True)\nvalid_loader = DataLoader(valid_set, batch_size=batch_size,  num_workers=8, pin_memory=True,shuffle=True)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-03T09:04:05.398256Z","iopub.execute_input":"2023-01-03T09:04:05.398639Z","iopub.status.idle":"2023-01-03T09:04:09.623928Z","shell.execute_reply.started":"2023-01-03T09:04:05.398596Z","shell.execute_reply":"2023-01-03T09:04:09.622874Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"6160\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\n\nclass Mydataset(Dataset):\n    def __init__(self, x ,y):\n        self.data=x\n        self.label=y\n    def __getitem__(self,idx):\n        return self.data[idx],self.label[idx]\n    def __len__(self):\n        return len(self.data)\n#半监督学习打伪标签\ndef pseudo_label(model,unlabel_set):\n    model.eval()\n    print(\"k\")\n    with torch.no_grad():\n        data_loader=DataLoader(unlabel_set,batch_size=128,shuffle=False)\n    for j,data in enumerate(data_loader):\n        inputs,_=data\n        inputs=inputs.to(\"cuda\")\n        outputs=model(inputs)\n        softmax=nn.Softmax(dim=-1)\n        labels=softmax(outputs)\n        _,labels=torch.max(labels,dim=1)\n      \n        if j==0:\n            dataset=Mydataset(x=inputs,y=labels)\n        else:\n            dataset_2=Mydataset(inputs,labels)\n            dataset=ConcatDataset([dataset,dataset_2])\n        gc.collect()\n        torch.cuda.empty_cache()\n    return dataset\n\n\n#网络结构\nclass Resblk1(nn.Module):\n    def __init__(self,ch_in,ch_out,k,s1,s2,p):\n        super(Resblk1,self).__init__()\n        self.conv0=nn.Conv2d(ch_in,ch_out,1,2,0)\n        self.conv1=nn.Conv2d(ch_in,ch_out,k,s1,p)\n        self.conv2=nn.Conv2d(ch_out,ch_out,k,s2,p)\n        self.relu=nn.ReLU()\n        self.bn=nn.BatchNorm2d(ch_out)\n\n    def forward(self,x):\n        x1=self.conv1(x)\n        x1=self.bn(x1)\n        x=self.conv0(x)\n        x=self.bn(x)\n        x1=self.relu(x1)\n        x1=self.conv2(x1)\n        x1=self.bn(x1)\n        x1=x1+x\n        x1=self.relu(x1)\n        return x1\n\nclass Resblk2(nn.Module):\n    def __init__(self,ch_in,ch_out,k,s1,s2,p):\n        super(Resblk2,self).__init__()\n        \n        self.conv1=nn.Conv2d(ch_in,ch_out,k,s1,p)\n        self.conv2=nn.Conv2d(ch_out,ch_out,k,s2,p)\n        self.relu=nn.ReLU()\n        self.bn=nn.BatchNorm2d(ch_out)\n\n    def forward(self,x):\n        x1=self.conv1(x)\n        x1=self.bn(x1)\n        x1=self.relu(x1)\n        x1=self.conv2(x1)\n        x1=self.bn(x1)\n        x1=x1+x\n        x1=self.relu(x1)\n        return x1        \n\n        \nclass Resnet(nn.Module):\n    def __init__(self):\n        super(Resnet,self).__init__()\n        self.conv=nn.Sequential(\n        nn.Conv2d(3,64,7,2,3),\n        nn.BatchNorm2d(64),\n        nn.MaxPool2d(3,2,1),\n        Resblk2(64,64,3,1,1,1),\n        Resblk2(64,64,3,1,1,1),\n        #Resblk1(64,128,3,2,1,1),\n        #Resblk2(128,128,3,1,1,1),\n        #Resblk1(128,256,3,2,1,1),\n        #Resblk2(256,256,3,1,1,1),\n        #Resblk1(256,512,3,2,1,1),\n        #Resblk2(512,512,3,1,1,1),\n        nn.AvgPool2d(7,stride=1)\n        )\n        self.fc=nn.Sequential(nn.Linear(26*26*64,11) \n                             )\n        \n    def forward(self,x):\n        x=self.conv(x)\n        x=x.flatten(1)\n        x=self.fc(x)\n        \n        return x\n\nLEARNING_RATE=0.0001\nEPOCH=80\n\nmodel=Resnet().to(\"cuda\")\ncriterion=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(model.parameters(),lr=LEARNING_RATE,weight_decay=1e-5)\n\n\n\n\n\ntrain_acc_list=[]\nval_acc_list=[]\ni=0\nsemi=False\nfor i in range(EPOCH):\n    train_acc=0.0\n    train_loss=0.0\n    val_acc=0.0\n    val_loss=0.0\n    \n    #网络训练\n    model.train()\n    for j,data in enumerate(train_loader):\n        inputs,labels=data\n       \n        inputs=inputs.to(\"cuda\")\n        labels=labels.to(\"cuda\")\n        outputs=model(inputs)\n        loss=criterion(outputs,labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        train_loss+=loss\n        _,pred=torch.max(outputs,dim=1)\n        train_acc+=(pred.cpu()==labels.cpu()).sum().item()\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    #半监督学习\n    if semi:\n        print(\"s\")\n        for k,data in enumerate(unlabeled_loader):\n            optimizer.zero_grad()\n            inputs,labels=data\n            inputs=inputs.to(\"cuda\")\n            labels=labels.to(\"cuda\")\n            outputs=model(inputs)\n            loss=criterion(outputs,labels)\n            loss.backward()\n            optimizer.step()\n    gc.collect()\n    torch.cuda.empty_cache()\n\n    #验证集\n    model.eval()\n    with torch.no_grad():\n        for j,data in enumerate(valid_loader):\n            inputs,labels=data\n            inputs=inputs.to(\"cuda\")\n            labels=labels.to(\"cuda\")\n            outputs=model(inputs)\n            loss=criterion(outputs,labels)\n            val_loss+=loss\n            _,pred=torch.max(outputs,dim=1)\n            val_acc+=(pred.cpu()==labels.cpu()).sum().item()\n    \n    #准确度和损失值    \n    train_acc=train_acc/len(train_set)\n    val_acc=val_acc/len(valid_set)\n    train_loss=train_loss/len(train_loader)\n    val_loss=val_loss/len(valid_loader)\n    train_acc_list.append(train_acc)\n    val_acc_list.append(val_acc)\n    print(i,\" t\",train_acc,\"v\",val_acc)\n    \n    #打伪标签\n    if(val_acc>1 and semi==False ):\n        unlabeled_sett=pseudo_label(model,unlabeled_set)\n        unlabeled_loader=DataLoader(unlabeled_sett, batch_size=batch_size, num_workers=0, shuffle=False)\n        semi=True\n\nplt.figure()\nx=range(0,80)\nplt.plot(x,train_acc_list, 'r-')\nplt.plot(x,val_acc_list,'r-',color='red')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-03T09:14:22.690003Z","iopub.execute_input":"2023-01-03T09:14:22.690420Z","iopub.status.idle":"2023-01-03T09:17:04.618773Z","shell.execute_reply.started":"2023-01-03T09:14:22.690384Z","shell.execute_reply":"2023-01-03T09:17:04.615261Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"0  t 0.2305194805194805 v 0.15\n1  t 0.3728896103896104 v 0.1787878787878788\n2  t 0.3961038961038961 v 0.16666666666666666\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3857407819.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m#网络训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}